#create an empty vector
Central_average_precip <- c()
# Adjusted pattern for "Percent of Average for this Date:"
if (length(central_pdf_text) > 0) {
for (sentence in central_pdf_text) {
pattern <- "(?i)Percent of Average for this Date[:\\s]+(.{4})"
next_four <- regmatches(sentence, regexpr(pattern, sentence, perl = TRUE))
if (length(next_four) > 0) {
# Append the value of next_four to the vector
Central_average_precip <- c(Central_average_precip, next_four)
cat(paste(next_four, "\n"))
} else {
cat("Next four characters after 'Percent of Average for this Date:' not found.\n")
}
}
} else {
cat("No text extracted from the PDF.")
}
#URL of pdf file
# ***** need to see if this pdf updates everyday with the same URL *******
snow_pack_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/swccond.pdf"
#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded
snow_pack_pdf_file<-"data_output/snow_pack.pdf"
# Download the PDF file
# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(snow_pack_pdf_url, snow_pack_pdf_file, mode = "wb")
# Extract text from the PDF
snow_pack_pdf_text <- pdf_text(snow_pack_pdf_file)
# Print the extracted text
print(snow_pack_pdf_text)
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)NORTH\\s{2,}(\\d+%).*?(\\d+%)"
# Extract the "NORTH" section
north_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))
# Check if the "NORTH" section is found
if (length(north_match) > 0) {
# Extract both percentages from the matched text
north_percentages <- regmatches(north_match[[1]], gregexpr("\\d+%", north_match[[1]]))[[1]]
# Print the extracted percentage
if (length(north_percentages) >= 2) {
cat(paste("Northern CA:", north_percentages[2], "of percent avgerage to date snow pack"))
} else {
cat("Second percentage in the 'NORTH' section not found.")
}
} else {
cat("NORTH section not found.")
}
# Define the pattern to match the line containing the snow water equivalent information
pattern <- "(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)"
# Extract the line containing snow water equivalent information
snow_water_line <- regmatches(snow_pack_pdf_text, regexpr(pattern, snow_pack_pdf_text, perl = TRUE))
# Check if the line is found
if (length(snow_water_line) > 0) {
# Extract the numeric value
numeric_value <- sub("(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)", "\\1", snow_water_line)
# Create the modified line with "inches" after the numeric value
modified_snow_water_line <- paste("average snow water equivalent", numeric_value, "inches")
cat("Northern Sierra", modified_snow_water_line, "\n")
} else {
cat("Snow water equivalent information not found.\n")
}
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)CENTRAL SIERRA\\s{2,}(\\d+%).*?(\\d+%)"
# Extract the "CENTRAL SIERRA" section
central_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))
# Check if the "CENTRAL SIERRA" section is found
if (length(central_match) > 0) {
# Extract both percentages from the matched text
central_percentages <- regmatches(central_match[[1]], gregexpr("\\d+%", central_match[[1]]))[[1]]
# Print the extracted percentage
if (length(central_percentages) >= 2) {
cat(paste("CENTRAL SIERRA", central_percentages[2], "of percent avg. to date snow pack"))
} else {
cat("Second percentage in the 'CENTRAL SIERRA' section not found.")
}
} else {
cat("CENTRAL SIERRA section not found.")
}
# Find the position of "Central Sierra" in the text
central_sierra_position <- regexpr("(?i)Central Sierra", snow_pack_pdf_text)
# If "Central Sierra" is found, find the position of "Average snow water equivalent (Inches)" after it
if (central_sierra_position > 0) {
# Get the substring starting from the position of "Central Sierra"
substring_after_central <- substring(snow_pack_pdf_text, central_sierra_position)
# Find the position of "Average snow water equivalent (Inches)" within the substring
snow_water_position <- regexpr("(?i)Average snow water equivalent \\(Inches\\)", substring_after_central)
# If "Average snow water equivalent (Inches)" is found, extract the numeric value following it
if (snow_water_position > 0) {
# Get the substring starting from the position of "Average snow water equivalent (Inches)"
snow_water_substring <- substring(substring_after_central, snow_water_position)
# Extract the numeric value following "Average snow water equivalent (Inches)"
snow_water_value <- regmatches(snow_water_substring, regexpr("\\d+\\.\\d+", snow_water_substring))
# If a numeric value is found, print it with the desired text
if (length(snow_water_value) > 0) {
cat(paste("Central snow water equivalent", snow_water_value))
} else {
cat("Snow water equivalent value not found.")
}
} else {
cat("Average snow water equivalent information not found for Central Sierra.")
}
} else {
cat("Central Sierra information not found.")
}
# Find the position of "State" in the text
state_position <- regexpr("(?i)State", snow_pack_pdf_text)
# If "State" is found, find the position of the numeric value after it
if (state_position > 0) {
# Get the substring starting from the position of "State"
substring_after_state <- substring(snow_pack_pdf_text, state_position)
# Extract the numeric value following "State"
snow_water_value <- regmatches(substring_after_state, regexpr("\\d+\\.\\d+", substring_after_state))
# If a numeric value is found, print it with the desired text
if (length(snow_water_value) > 0) {
cat(paste("State wide average snow pack", snow_water_value))
} else {
cat("Snow water equivalent value not found.")
}
} else {
cat("State information not found.")
}
# Find the position of "Statewide Average:" in the text
statewide_position <- regexpr("(?i)Statewide Average:", snow_pack_pdf_text)
# If "Statewide Average:" is found, find the position of the numeric value after it
if (statewide_position > 0) {
# Get the substring starting from the position of "Statewide Average:"
substring_after_statewide <- substring(snow_pack_pdf_text, statewide_position)
# Extract both percentages from the matched text
statewide_percentages <- regmatches(substring_after_statewide, gregexpr("\\d+%", substring_after_statewide))[[1]]
# Print the second percentage with the desired text
if (length(statewide_percentages) >= 2) {
cat("Statewide average percent snow pack for this date", statewide_percentages[2], "\n")
} else {
cat("Second percentage after 'Statewide Average:' not found.")
}
} else {
cat("Statewide Average information not found.\n")
}
file.exists("geo_files/legal_delta.geojson")
# Load the Legal Delta boundary (replace with your actual file path)
legal_delta_boundary <- geojson_read("geo_files/legal_delta.geojson", what = "sp")
# Create the map with Legal Delta boundary and specific points
leaflet() %>%
addTiles() %>%
setView(lng = -121.5, lat = 38.05, zoom = 7) %>%  # Center the map
# Add the Legal Delta boundary polygon
addPolygons(data = legal_delta_boundary, color = "blue", weight = 2, fillOpacity = 0.5, popup = "Legal Delta Boundary") %>%
# Add specific points of interest as markers
addMarkers(lng = -121.493000, lat = 39.540000, popup = "Oroville Reservoir") %>%  # Oroville reservoir (ORO)
addMarkers(lng = 	-119.302000, lat = 	37.145000, popup = "Shasta Reservoir") %>%    # Shasta reservoir (SHA)
addMarkers(lng = -121.133000, lat = 37.033000, popup = "San Luis Reservoir")   # San Luis reservoir (SNL)
# URL of the website to scrape
reservoir_url <- "https://cdec.water.ca.gov/reportapp/javareports?name=RES"
# Read the web page
reservoir_web_page <- read_html(reservoir_url)
# Extract the table node
reservoir_table_node <- html_node(reservoir_web_page, "table")
# Extract the table content into a data frame
reservoir_table_data <- html_table(reservoir_table_node)
# Print the entire table data
print(reservoir_table_data)
# Extract a specific numbers [row, column]
# Shasta (at Sacramento River)
# extract percent of average storage
shasta_percent_average_storage_value <- as.numeric(reservoir_table_data[10, 9])
# extract percent of capacity
shasta_percent_capacity_value <- as.numeric(reservoir_table_data[10, 7])
# Print the formatted output with a Markdown header
cat(sprintf(" Shasta Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n",
shasta_percent_average_storage_value, shasta_percent_capacity_value))
# Extract a specific numbers [row, column]
# Oroville (at Feather River)
# extract percent of average storage
oroville_percent_average_storage_value <- as.numeric(reservoir_table_data[13, 9])
# extract percent of capacity
oroville_percent_capacity_value <- as.numeric(reservoir_table_data[13, 7])
# Print the formatted output (but this will be hidden)
cat(sprintf(" Oroville Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n",
oroville_percent_average_storage_value, oroville_percent_capacity_value))
# Extract a specific numbers [row, column]
# San Luis (at San Luis Creek)
# extract percent of average storage
SanLuis_percent_average_storage_value <- as.numeric(reservoir_table_data[56, 9])
# extract percent of capacity
SanLuis_percent_capacity_value <- as.numeric(reservoir_table_data[56, 7])
# Print the formatted output (but this will be hidden)
cat(sprintf(" San Luis Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n",
SanLuis_percent_average_storage_value, SanLuis_percent_capacity_value))
#map of sensors
map <- leaflet() %>%
addTiles() %>%
setView(lng = -121.5, lat = 38.05, zoom = 9) %>% # Adjust center and zoom for the Legal Delta
addMarkers(lng = -121.5, lat = 38.05, popup = "Central Delta Region") %>% # Add specific points
addMarkers(lng = -121.7, lat = 38.3, popup = "North Delta") %>%          # Another example point
addMarkers(lng = -121.3, lat = 37.9, popup = "South Delta")               # Example points
map
# File path to your Excel file
sacramento_file_path <- "historical_data/historical_data_full.xlsx"
# Determine the current month and year
sacramento_current_month <- format(Sys.Date(), "%b")
sacramento_current_year <- format(Sys.Date(), "%Y")
# Load the entire workbook without overwriting other sheets
sacramento_workbook <- loadWorkbook(sacramento_file_path)
# Read the specific sheet you want to update
sacramento_historical_data <- readWorkbook(sacramento_workbook, sheet = "Flow_Sac")
sacramento_historical_data$Year <- as.character(sacramento_historical_data$Year) # Ensure Year is character
# Define the start and end dates for the current month
sacramento_start_date <- floor_date(Sys.Date(), "month")
sacramento_end_date <- Sys.Date()
# Query CDEC data for Sacramento at Freeport (station "FPT") for the current month
sacramento_flow_daily <- cdec_query(station = "FPT", sensor_num = 20,
dur_code = "H", start_date = as.character(sacramento_start_date),
end_date = as.character(sacramento_end_date))
# Calculate the monthly average for Sacramento flow
sacramento_export_monthly_average <- mean(sacramento_flow_daily$parameter_value, na.rm = TRUE)
# Calculate the historical mean for the current month, if available in your data
sacramento_current_month_historical_data <- sacramento_historical_data %>%
filter(Month == sacramento_current_month) %>%
select(Average_Flow_Daily)
sacramento_current_month_historical_mean <- mean(sacramento_current_month_historical_data$Average_Flow_Daily, na.rm = TRUE)
# Calculate the percentage of the current month’s average relative to the historical average
sacramento_percentage_of_cfs_average <- (sacramento_export_monthly_average / sacramento_current_month_historical_mean) * 100
# Print only the percentage result
message(sprintf("Sacramento export monthly average is %.2f%% of the historical average for %s",
sacramento_percentage_of_cfs_average, sacramento_current_month))
# Check if there is an entry for the current month and year
existing_entry <- sacramento_historical_data %>%
filter(Month == sacramento_current_month, Year == sacramento_current_year)
suppressMessages({
if (nrow(existing_entry) > 0) {
# Update the existing row with the new flow average for the current month
row_to_update <- which(sacramento_historical_data$Month == sacramento_current_month &
sacramento_historical_data$Year == sacramento_current_year)
sacramento_historical_data[row_to_update, "Average_Flow_Daily"] <- sacramento_export_monthly_average
} else {
# Create a new row with the current month, year, and flow average if it's a new month
new_row <- data.frame(
Month = sacramento_current_month,
Year = sacramento_current_year,
Average_Flow_Daily = sacramento_export_monthly_average
)
# Append the new row to the historical data
sacramento_historical_data <- bind_rows(sacramento_historical_data, new_row)
}
# Write only the modified sheet back to the workbook
writeData(sacramento_workbook, sheet = "Flow_Sac", x = sacramento_historical_data)
# Save the workbook, preserving all other sheets
saveWorkbook(sacramento_workbook, sacramento_file_path, overwrite = TRUE)
})
# File path to your Excel file (the one you just uploaded)
san_joaquin_file_path <- "historical_data/historical_data_full.xlsx"
# Determine the current month and year
san_joaquin_current_month <- format(Sys.Date(), "%b")
san_joaquin_current_year <- format(Sys.Date(), "%Y")
# Load the entire workbook without overwriting other sheets
san_joaquin_workbook <- loadWorkbook(san_joaquin_file_path)
# Read the specific sheet you want to update
san_joaquin_historical_data <- readWorkbook(san_joaquin_workbook, sheet = "Flow_SanJoaq")
san_joaquin_historical_data$Year <- as.character(san_joaquin_historical_data$Year) # Ensure Year is character
# Define the start and end dates for the current month
san_joaquin_start_date <- floor_date(Sys.Date(), "month")
san_joaquin_end_date <- Sys.Date()
# Query CDEC data for San Joaquin at Vernalis (station "VNS") for the current month
# Assuming `cdec_query` returns a data frame with a "parameter_value" column
san_joaquin_flow_daily <- cdec_query(station = "VNS", sensor_num = 20,
dur_code = "H", start_date = as.character(san_joaquin_start_date),
end_date = as.character(san_joaquin_end_date))
# Calculate the monthly average for San Joaquin flow
san_joaquin_export_monthly_average <- mean(san_joaquin_flow_daily$parameter_value, na.rm = TRUE)
# Calculate the historical mean for the current month, if available in your data
san_joaquin_current_month_historical_data <- san_joaquin_historical_data %>%
filter(Month == san_joaquin_current_month) %>%
select(Average_Flow_Daily)
san_joaquin_current_month_historical_mean <- mean(san_joaquin_current_month_historical_data$Average_Flow_Daily, na.rm = TRUE)
# Calculate the percentage of the current month’s average relative to the historical average
san_joaquin_percentage_of_cfs_average <- (san_joaquin_export_monthly_average / san_joaquin_current_month_historical_mean) * 100
# Print only the percentage result
message(sprintf("San Joaquin export monthly average is %.2f%% of the historical average for %s",
san_joaquin_percentage_of_cfs_average, san_joaquin_current_month))
# Check if there is an entry for the current month and year
existing_entry <- san_joaquin_historical_data %>%
filter(Month == san_joaquin_current_month, Year == san_joaquin_current_year)
suppressMessages({
if (nrow(existing_entry) > 0) {
# Update the existing row with the new flow average for the current month
row_to_update <- which(san_joaquin_historical_data$Month == san_joaquin_current_month &
san_joaquin_historical_data$Year == san_joaquin_current_year)
san_joaquin_historical_data[row_to_update, "Average_Flow_Daily"] <- san_joaquin_export_monthly_average
} else {
# Create a new row with the current month, year, and flow average if it's a new month
new_row <- data.frame(
Month = san_joaquin_current_month,
Year = san_joaquin_current_year,
Average_Flow_Daily = san_joaquin_export_monthly_average
)
# Append the new row to the historical data
san_joaquin_historical_data <- bind_rows(san_joaquin_historical_data, new_row)
}
# Write only the modified sheet back to the workbook
writeData(san_joaquin_workbook, sheet = "Flow_SanJoaq", x = san_joaquin_historical_data)
# Save the workbook, preserving all other sheets
saveWorkbook(san_joaquin_workbook, san_joaquin_file_path, overwrite = TRUE)
})
# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"
# Path to save the downloaded PDF file
delta_exports_pdf_file <- "historical_data/delta_exports.pdf"
# Download the PDF file
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")
# Extract text from the PDF file
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)
# Extract the last page's text, where the "Average" row appears
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]
# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\n")[[1]]
# Find the line containing the "Average" row
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]
# Print the line to verify the content and ensure we're targeting the right row
print(delta_export_average_line)
# Refine the regular expression to match specific numeric values, using longer patterns if possible
delta_export_values <- str_extract_all(delta_export_average_line, "\\b\\d{4,5}\\b")[[1]]  # Look for 4- or 5-digit numbers
# Inspect extracted values to identify the target (in this case, 5259 is expected)
print(delta_export_values)
# Assuming the correct index is known based on inspection, retrieve the value (e.g., 5259)
average_delta_export_value <- as.numeric(delta_export_values[1])  # Adjust the index if necessary
print(average_delta_export_value)
# Excel file path and current date
excel_file_path <- "historical_data/historical_data_full.xlsx"
current_month <- format(Sys.Date(), "%b")
current_year <- format(Sys.Date(), "%Y")
# Load the workbook and the specific sheet
delta_exports_workbook <- loadWorkbook(excel_file_path)
delta_exports_data <- readWorkbook(delta_exports_workbook, sheet = "Total_Delta_Exports")
# Ensure the Year column is character to match with the new data format
delta_exports_data$Year <- as.character(delta_exports_data$Year)
# Check if there's already an entry for the current month and year
existing_entry <- delta_exports_data %>%
filter(Month == current_month, Year == current_year)
if (nrow(existing_entry) > 0) {
# Update the existing row with the new average Delta Exports value
row_to_update <- which(delta_exports_data$Month == current_month &
delta_exports_data$Year == current_year)
delta_exports_data[row_to_update, "Exports"] <- average_delta_export_value
} else {
# Add a new row if it's a new month
new_row <- data.frame(
Month = current_month,
Year = current_year,
Exports = average_delta_export_value
)
# Append the new row
delta_exports_data <- bind_rows(delta_exports_data, new_row)
}
# Write the updated sheet back to the workbook
writeData(delta_exports_workbook, sheet = "Total_Delta_Exports", x = delta_exports_data)
# Save the workbook, preserving all sheets
saveWorkbook(delta_exports_workbook, excel_file_path, overwrite = TRUE)
message("Delta Exports data updated successfully for the current month.")
# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"
# Path to save the downloaded PDF file
delta_exports_pdf_file <- "historical_data/delta_exports.pdf"
# Download the PDF file
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")
# Extract text from the PDF file
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)
# Extract the last page's text, where the "Average" row appears
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]
# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\n")[[1]]
# Find the line containing the "Average" row
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]
# Print the line to verify the content and ensure we're targeting the right row
print(delta_export_average_line)
# Refine the regular expression to match specific numeric values, using longer patterns if possible
delta_export_values <- str_extract_all(delta_export_average_line, "\\b\\d{4,5}\\b")[[1]]  # Look for 4- or 5-digit numbers
# Inspect extracted values to identify the target (in this case, 5259 is expected)
print(delta_export_values)
# Assuming the correct index is known based on inspection, retrieve the value (e.g., 5259)
average_delta_export_value <- as.numeric(delta_export_values[1])  # Adjust the index if necessary
print(average_delta_export_value)
# Excel file path and current date
excel_file_path <- "historical_data/historical_data_full.xlsx"
current_month <- format(Sys.Date(), "%b")
current_year <- format(Sys.Date(), "%Y")
# Load the workbook and the specific sheet
delta_exports_workbook <- loadWorkbook(excel_file_path)
delta_exports_data <- readWorkbook(delta_exports_workbook, sheet = "Total_Delta_Exports")
# Ensure the Year column is character to match with the new data format
delta_exports_data$Year <- as.character(delta_exports_data$Year)
# Check if there's already an entry for the current month and year
existing_entry <- delta_exports_data %>%
filter(Month == current_month, Year == current_year)
if (nrow(existing_entry) > 0) {
# Update the existing row with the new average Delta Exports value
row_to_update <- which(delta_exports_data$Month == current_month &
delta_exports_data$Year == current_year)
delta_exports_data[row_to_update, "Exports"] <- average_delta_export_value
} else {
# Add a new row if it's a new month
new_row <- data.frame(
Month = current_month,
Year = current_year,
Exports = average_delta_export_value
)
# Append the new row
delta_exports_data <- bind_rows(delta_exports_data, new_row)
}
# Write the updated sheet back to the workbook
writeData(delta_exports_workbook, sheet = "Total_Delta_Exports", x = delta_exports_data)
# Save the workbook, preserving all sheets
saveWorkbook(delta_exports_workbook, excel_file_path, overwrite = TRUE)
message("Delta Exports data updated successfully for the current month.")
# File path to your Excel file
total_delta_exports_file_path <- "historical_data/historical_data_full.xlsx"
# Determine the current month and year
total_delta_exports_current_month <- format(Sys.Date(), "%b")
total_delta_exports_current_year <- format(Sys.Date(), "%Y")
# Load the entire workbook without overwriting other sheets
total_delta_exports_workbook <- loadWorkbook(total_delta_exports_file_path)
# Read the specific sheet you want to update
total_delta_exports_data <- readWorkbook(total_delta_exports_workbook, sheet = "Total_Delta_Exports")
total_delta_exports_data$Year <- as.character(total_delta_exports_data$Year) # Ensure Year is character
# Define the start and end dates for the current month
total_delta_exports_start_date <- floor_date(Sys.Date(), "month")
total_delta_exports_end_date <- Sys.Date()
# Extract the average delta export value from the PDF
# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"
# Path to save the downloaded PDF file
delta_exports_pdf_file <- "historical_data/delta_exports.pdf"
# Download the PDF file
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")
# Extract text from the PDF file
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)
# Extract the last page's text, where the "Average" row appears
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]
# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\n")[[1]]
# Find the line containing the "Average" row
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]
# Extract numeric values from the line
delta_export_values <- str_extract_all(delta_export_average_line, "\b\d{4,5}\b")[[1]]  # Look for 4- or 5-digit numbers
# File path to your Excel file
total_delta_exports_file_path <- "historical_data/historical_data_full.xlsx"
# Determine the current month and year
total_delta_exports_current_month <- format(Sys.Date(), "%b")
total_delta_exports_current_year <- format(Sys.Date(), "%Y")
# Load the entire workbook without overwriting other sheets
total_delta_exports_workbook <- loadWorkbook(total_delta_exports_file_path)
# Read the specific sheet you want to update
total_delta_exports_data <- readWorkbook(total_delta_exports_workbook, sheet = "Total_Delta_Exports")
total_delta_exports_data$Year <- as.character(total_delta_exports_data$Year) # Ensure Year is character
# Define the start and end dates for the current month
total_delta_exports_start_date <- floor_date(Sys.Date(), "month")
total_delta_exports_end_date <- Sys.Date()
# Extract the average delta export value from the PDF
# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"
# Path to save the downloaded PDF file
delta_exports_pdf_file <- "historical_data/delta_exports.pdf"
# Download the PDF file
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")
# Extract text from the PDF file
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)
# Extract the last page's text, where the "Average" row appears
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]
# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\n")[[1]]
# Find the line containing the "Average" row
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]
# Print extracted line for debugging
print(delta_export_average_line)
# Extract 4- or 5-digit numbers safely
delta_export_values <- str_extract_all(delta_export_average_line, "\\b\\d{4,5}\\b")[[1]]
# Print extracted values to verify
print(delta_export_values)
# Convert to numeric, handling potential errors
if (length(delta_export_values) > 0) {
average_delta_export_value <- as.numeric(delta_export_values[1])
} else {
stop("No valid numerical values found in the extracted line.")
}
print(delta_export_average_line)
# File path to save the PDF
delta_exports_pdf_file <- "historical_data/delta_exports.pdf"
# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"
# Download the PDF
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")
# Extract text from the PDF
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)
# Extract the last page's text (where the "Average" row is located)
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]
# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\n")[[1]]
# Identify the line containing "Average"
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]
# Print extracted line for debugging
print(delta_export_average_line)
# Extract the first large numeric value (allowing commas)
delta_export_values <- str_extract(delta_export_average_line, "\\d{1,3}(,\\d{3})*")
# Remove commas and convert to numeric
if (!is.na(delta_export_values)) {
average_delta_export_value <- as.numeric(gsub(",", "", delta_export_values))
} else {
warning("No valid numerical values found in the extracted line. Check the PDF format.")
average_delta_export_value <- NA
}
# Print the final extracted value
print(average_delta_export_value)
