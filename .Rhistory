delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)
# Extract the last page's text
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]
# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\\n")[[1]]
# Find the line containing the "Average" row
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]
# Define delta_export_numbers before use
delta_export_numbers <- str_split(delta_export_average_line, "\\s+")[[1]]
# Print extracted elements for debugging
print(delta_export_numbers)
# Extract numeric values
numeric_values <- delta_export_numbers[str_detect(delta_export_numbers, "^\\d{1,5}[,\\.]?\\d*$")]
# Print numeric values for debugging
print(numeric_values)
# Extract the 17th numeric value
if (length(numeric_values) >= 14) {
average_delta_export_value <- as.numeric(gsub(",", "", numeric_values[14]))
} else {
warning("Could not find the 14th numeric value. Check the PDF format.")
average_delta_export_value <- NA
}
# Print the final extracted value
print(average_delta_export_value)
# Excel file path and current date
excel_file_path <- "historical_data/historical_data_full.xlsx"
current_month <- format(Sys.Date(), "%b")
current_year <- format(Sys.Date(), "%Y")
# Load workbook and sheet
delta_exports_workbook <- loadWorkbook(excel_file_path)
delta_exports_data <- readWorkbook(delta_exports_workbook, sheet = "Total_Delta_Exports")
delta_exports_data$Year <- as.character(delta_exports_data$Year)
# Check for existing entry
existing_entry <- delta_exports_data %>%
filter(Month == current_month, Year == current_year)
if (nrow(existing_entry) > 0) {
row_to_update <- which(delta_exports_data$Month == current_month &
delta_exports_data$Year == current_year)
delta_exports_data[row_to_update, "Exports"] <- average_delta_export_value
} else {
new_row <- data.frame(
Month = current_month,
Year = current_year,
Exports = average_delta_export_value
)
delta_exports_data <- bind_rows(delta_exports_data, new_row)
}
# Write updated sheet back to the workbook
writeData(delta_exports_workbook, sheet = "Total_Delta_Exports", x = delta_exports_data)
# Save the workbook
saveWorkbook(delta_exports_workbook, excel_file_path, overwrite = TRUE)
# Determine the current month and year
delta_export_current_month <- format(Sys.Date(), "%b")
delta_export_current_year <- format(Sys.Date(), "%Y")
# Load the entire workbook without overwriting other sheets
delta_export_workbook <- loadWorkbook(san_joaquin_file_path)
# Excel file path and current date
delta_export_file_path <- "historical_data/historical_data_full.xlsx"
# Load the entire workbook without overwriting other sheets
delta_export_workbook <- loadWorkbook(san_joaquin_file_path)
# Load the entire workbook without overwriting other sheets
delta_export_workbook <- loadWorkbook(delta_export_file_path)
# Read the specific sheet you want to update
delta_export_historical_data <- readWorkbook(delta_export_workbook, sheet = "Flow_SanJoaq")
delta_export_historical_data$Year <- as.character(delta_export_historical_data$Year) # Ensure Year is character
# Calculate the historical mean for the current month, if available in your data
delta_export_current_month_historical_data <- delta_export_historical_data %>%
filter(Month == delta_export_current_month) %>%
select(Average_Flow_Daily)
delta_export_current_month_historical_data
delta_export_current_month_historical_mean <- mean(delta_export_current_month_historical_data$Average_Flow_Daily, na.rm = TRUE)
delta_export_current_month_historical_mean
# Calculate the percentage of the current month’s average relative to the historical average
delta_export_percentage_of_cfs_average <- (delta_export_export_monthly_average / delta_export_current_month_historical_mean) * 100
# Calculate the percentage of the current month’s average relative to the historical average
delta_export_percentage_of_cfs_average <- (average_delta_export_value / delta_export_current_month_historical_mean) * 100
delta_export_percentage_of_cfs_average
# Print only the percentage result
message(sprintf("Total Delta export monthly average is %.2f%% of the historical average for %s",
delta_export_percentage_of_cfs_average, delta_export_current_month))
rm(list=ls())
library(rvest)
library(pdftools)
library(tidyverse)
library(stringr)
library(rvest)
library(xml2)
library(CDECRetrieve)
library(magrittr)
library(leaflet)
library(writexl)
library(readxl)
library(lubridate)
library(openxlsx)
library(geojsonio)
#options(repos = c(
# sbashevkin = 'https://sbashevkin.r-universe.dev',
#  CRAN = 'https://cloud.r-project.org'))
#install.packages("deltamapr")
library(deltamapr)
# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"
# Path to save the downloaded PDF file
delta_exports_pdf_file <- "historical_data/delta_exports.pdf"
# Download the PDF file
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")
# Extract text from the PDF file
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)
# Extract the last page's text
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]
# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\\n")[[1]]
# Find the line containing the "Average" row
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]
# Define delta_export_numbers before use
delta_export_numbers <- str_split(delta_export_average_line, "\\s+")[[1]]
# Print extracted elements for debugging
print(delta_export_numbers)
# Extract numeric values
numeric_values <- delta_export_numbers[str_detect(delta_export_numbers, "^\\d{1,5}[,\\.]?\\d*$")]
# Print numeric values for debugging
print(numeric_values)
# Extract the 17th numeric value
if (length(numeric_values) >= 14) {
average_delta_export_value <- as.numeric(gsub(",", "", numeric_values[14]))
} else {
warning("Could not find the 14th numeric value. Check the PDF format.")
average_delta_export_value <- NA
}
# Print the final extracted value
print(average_delta_export_value)
# Excel file path and current date
delta_export_file_path <- "historical_data/historical_data_full.xlsx"
current_month <- format(Sys.Date(), "%b")
current_year <- format(Sys.Date(), "%Y")
# Load workbook and sheet
delta_exports_workbook <- loadWorkbook(delta_export_file_path)
delta_exports_data <- readWorkbook(delta_exports_workbook, sheet = "Total_Delta_Exports")
delta_exports_data$Year <- as.character(delta_exports_data$Year)
# Check for existing entry
existing_entry <- delta_exports_data %>%
filter(Month == current_month, Year == current_year)
if (nrow(existing_entry) > 0) {
row_to_update <- which(delta_exports_data$Month == current_month &
delta_exports_data$Year == current_year)
delta_exports_data[row_to_update, "Exports"] <- average_delta_export_value
} else {
new_row <- data.frame(
Month = current_month,
Year = current_year,
Exports = average_delta_export_value
)
delta_exports_data <- bind_rows(delta_exports_data, new_row)
}
# Write updated sheet back to the workbook
writeData(delta_exports_workbook, sheet = "Total_Delta_Exports", x = delta_exports_data)
# Save the workbook
saveWorkbook(delta_exports_workbook, excel_file_path, overwrite = TRUE)
# Save the workbook
saveWorkbook(delta_exports_workbook, delta_export_file_path, overwrite = TRUE)
# Determine the current month and year
delta_export_current_month <- format(Sys.Date(), "%b")
delta_export_current_year <- format(Sys.Date(), "%Y")
# Load the entire workbook without overwriting other sheets
delta_export_workbook <- loadWorkbook(delta_export_file_path)
# Read the specific sheet you want to update
delta_export_historical_data <- readWorkbook(delta_export_workbook, sheet = "Flow_SanJoaq")
delta_export_historical_data$Year <- as.character(delta_export_historical_data$Year) # Ensure Year is character
# Calculate the historical mean for the current month, if available in your data
delta_export_current_month_historical_data <- delta_export_historical_data %>%
filter(Month == delta_export_current_month) %>%
select(Average_Flow_Daily)
delta_export_current_month_historical_mean <- mean(delta_export_current_month_historical_data$Average_Flow_Daily, na.rm = TRUE)
delta_export_current_month_historical_mean
# Calculate the percentage of the current month’s average relative to the historical average
delta_export_percentage_of_cfs_average <- (average_delta_export_value / delta_export_current_month_historical_mean) * 100
delta_export_percentage_of_cfs_average
# Print only the percentage result
message(sprintf("Total Delta export monthly average is %.2f%% of the historical average for %s",
delta_export_percentage_of_cfs_average, delta_export_current_month))
knitr::opts_chunk$set(echo = FALSE)
rm(list=ls())
library(rvest)
library(pdftools)
library(tidyverse)
library(stringr)
library(rvest)
library(xml2)
library(CDECRetrieve)
library(magrittr)
library(leaflet)
library(writexl)
library(readxl)
library(lubridate)
library(openxlsx)
library(geojsonio)
#options(repos = c(
# sbashevkin = 'https://sbashevkin.r-universe.dev',
#  CRAN = 'https://cloud.r-project.org'))
#install.packages("deltamapr")
library(deltamapr)
#URL of pdf file
#assigns a string value to the url
northern_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/PLOT_ESI.pdf"
#file pathway to save the pdf
northern_pdf_file <- "data_output/northern_sierra.pdf"
#saves file to specified destination
# wb means 'write binary mode' used for things that are non-text files (ex: pdfs)
download.file(northern_pdf_url, northern_pdf_file, mode = "wb")
# Extract text from the PDF from the file location
#returns it as a character vector
northern_pdf_text <- pdf_text(northern_pdf_file)
# Prints the extracted text (keep unchecked)
#print(northern_pdf_text)
# Extract text from the PDF file
northern_pdf_text <- pdf_text(northern_pdf_file)
# Define the pattern to extract the number next to "Current:"
pattern <- "(?i)Current:\\s?(.{4})"  #(.{4}) indicates that we are looking for 4 characters after 'Current'
#?i indicates case sensitive for the word 'Current:' "\\s?" matches white space after
# Initialize a variable to store the extracted number
N_sierra_current_precip <- NULL
# Search for the pattern in the text
if (length(northern_pdf_text) > 0) {
for (sentence in northern_pdf_text) { #sentence is a tempory placeholder for the term we are looking for
match <- regexpr(pattern, sentence, perl = TRUE)
if (match[1] != -1) {
# Extract the number using the captured group
northern_next_four <- regmatches(sentence, match)
N_sierra_current_precip <- sub(pattern, "\\1", northern_next_four)
cat(paste(N_sierra_current_precip, "inches\n"))
break  # Stop the loop after finding the first match of Current and the 4 numbers after it
}
}
} else {
cat("No text extracted from the PDF.")
}
# Create an empty vector to store the extracted value
N_sierra_average_precip <- c()
# Extract text from the PDF file
northern_pdf_text <- pdf_text(northern_pdf_file)
# Check if the PDF text is not empty
if (length(northern_pdf_text) > 0) {
# Concatenate all the text into a single string
combined_text <- paste(northern_pdf_text, collapse = " ")
# Define the pattern to match the "Percent of Average for this Date:" followed by the percentage value
pattern <- "(?i)Percent of Average for this Date:\\s*(\\d+%)"
# Extract the match using regmatches and regexpr
northern_next_four <- regmatches(combined_text, regexpr(pattern, combined_text, perl = TRUE))
if (length(northern_next_four) > 0) {
# Extract the percentage value using a capturing group
percent_value <- sub("(?i)Percent of Average for this Date:\\s*(\\d+%)", "\\1", northern_next_four)
# Append the value to the vector
N_sierra_average_precip <- c(N_sierra_average_precip, percent_value)
# Print only the percentage value
cat(percent_value, "\n")
} else {
cat("Percent of Average for this Date not found.\n")
}
} else {
cat("No text extracted from the PDF.\n")
}
#Central Sierra precipitation #Pulling and downloading the pdf from online
#URL of pdf file
# ***** need to see if this pdf updates everyday with the same URL *******
central_ppt_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/PLOT_FSI.pdf"
#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded
central_ppt_pdf_file2<-"data_output/central_sierra2.pdf"
# Download the PDF file
# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(central_ppt_pdf_url, central_ppt_pdf_file2, mode = "wb")
# Extract text from the PDF
central_pdf_text <- pdf_text(central_ppt_pdf_file2)
# Print the extracted text
print(central_pdf_text)
# Create an empty vector
Central_current_precip <- c()
# Adjusted pattern for "Current:"
if (length(central_pdf_text) > 0) {
for (sentence in central_pdf_text) {
# Pattern to match "Current:" and capture the 4 characters after it
pattern <- "(?i)Current[:\\s]+(.{4})"
# Extract the matched text
next_four <- regmatches(sentence, regexpr(pattern, sentence, perl = TRUE))
if (length(next_four) > 0) {
# Extract only the captured group (the 4 characters) and not "Current:"
number_only <- sub(pattern, "\\1", next_four)
# Append the value of number_only to the vector
Central_current_precip <- c(Central_current_precip, number_only)
# Print only the number
cat(paste(number_only, "inches\n"))
} else {
cat("Next four characters after 'Current:' not found.\n")
}
}
} else {
cat("No text extracted from the PDF.\n")
}
#Central Sierra #PUlling out Percent average
#create an empty vector
Central_average_precip <- c()
# Adjusted pattern for "Percent of Average for this Date:"
if (length(central_pdf_text) > 0) {
for (sentence in central_pdf_text) {
pattern <- "(?i)Percent of Average for this Date[:\\s]+(.{4})"
next_four <- regmatches(sentence, regexpr(pattern, sentence, perl = TRUE))
if (length(next_four) > 0) {
# Append the value of next_four to the vector
Central_average_precip <- c(Central_average_precip, next_four)
cat(paste(next_four, "\n"))
} else {
cat("Next four characters after 'Percent of Average for this Date:' not found.\n")
}
}
} else {
cat("No text extracted from the PDF.")
}
#URL of pdf file
# ***** need to see if this pdf updates everyday with the same URL *******
snow_pack_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/swccond.pdf"
#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded
snow_pack_pdf_file<-"data_output/snow_pack.pdf"
# Download the PDF file
# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(snow_pack_pdf_url, snow_pack_pdf_file, mode = "wb")
# Extract text from the PDF
snow_pack_pdf_text <- pdf_text(snow_pack_pdf_file)
# Print the extracted text
print(snow_pack_pdf_text)
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)NORTH\\s{2,}(\\d+%).*?(\\d+%)"
# Extract the "NORTH" section
north_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))
# Check if the "NORTH" section is found
if (length(north_match) > 0) {
# Extract both percentages from the matched text
north_percentages <- regmatches(north_match[[1]], gregexpr("\\d+%", north_match[[1]]))[[1]]
# Print the extracted percentage
if (length(north_percentages) >= 2) {
cat(paste("Northern CA:", north_percentages[2], "of percent avgerage to date snow pack"))
} else {
cat("Second percentage in the 'NORTH' section not found.")
}
} else {
cat("NORTH section not found.")
}
# Define the pattern to match the line containing the snow water equivalent information
pattern <- "(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)"
# Extract the line containing snow water equivalent information
snow_water_line <- regmatches(snow_pack_pdf_text, regexpr(pattern, snow_pack_pdf_text, perl = TRUE))
# Check if the line is found
if (length(snow_water_line) > 0) {
# Extract the numeric value
numeric_value <- sub("(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)", "\\1", snow_water_line)
# Create the modified line with "inches" after the numeric value
modified_snow_water_line <- paste("average snow water equivalent", numeric_value, "inches")
cat("Northern Sierra", modified_snow_water_line, "\n")
} else {
cat("Snow water equivalent information not found.\n")
}
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)CENTRAL SIERRA\\s{2,}(\\d+%).*?(\\d+%)"
# Extract the "CENTRAL SIERRA" section
central_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))
# Check if the "CENTRAL SIERRA" section is found
if (length(central_match) > 0) {
# Extract both percentages from the matched text
central_percentages <- regmatches(central_match[[1]], gregexpr("\\d+%", central_match[[1]]))[[1]]
# Print the extracted percentage
if (length(central_percentages) >= 2) {
cat(paste("CENTRAL SIERRA", central_percentages[2], "of percent avg. to date snow pack"))
} else {
cat("Second percentage in the 'CENTRAL SIERRA' section not found.")
}
} else {
cat("CENTRAL SIERRA section not found.")
}
# Find the position of "Central Sierra" in the text
central_sierra_position <- regexpr("(?i)Central Sierra", snow_pack_pdf_text)
# If "Central Sierra" is found, find the position of "Average snow water equivalent (Inches)" after it
if (central_sierra_position > 0) {
# Get the substring starting from the position of "Central Sierra"
substring_after_central <- substring(snow_pack_pdf_text, central_sierra_position)
# Find the position of "Average snow water equivalent (Inches)" within the substring
snow_water_position <- regexpr("(?i)Average snow water equivalent \\(Inches\\)", substring_after_central)
# If "Average snow water equivalent (Inches)" is found, extract the numeric value following it
if (snow_water_position > 0) {
# Get the substring starting from the position of "Average snow water equivalent (Inches)"
snow_water_substring <- substring(substring_after_central, snow_water_position)
# Extract the numeric value following "Average snow water equivalent (Inches)"
snow_water_value <- regmatches(snow_water_substring, regexpr("\\d+\\.\\d+", snow_water_substring))
# If a numeric value is found, print it with the desired text
if (length(snow_water_value) > 0) {
cat(paste("Central snow water equivalent", snow_water_value))
} else {
cat("Snow water equivalent value not found.")
}
} else {
cat("Average snow water equivalent information not found for Central Sierra.")
}
} else {
cat("Central Sierra information not found.")
}
# Find the position of "State" in the text
state_position <- regexpr("(?i)State", snow_pack_pdf_text)
# If "State" is found, find the position of the numeric value after it
if (state_position > 0) {
# Get the substring starting from the position of "State"
substring_after_state <- substring(snow_pack_pdf_text, state_position)
# Extract the numeric value following "State"
snow_water_value <- regmatches(substring_after_state, regexpr("\\d+\\.\\d+", substring_after_state))
# If a numeric value is found, print it with the desired text
if (length(snow_water_value) > 0) {
cat(paste("State wide average snow pack", snow_water_value))
} else {
cat("Snow water equivalent value not found.")
}
} else {
cat("State information not found.")
}
# Find the position of "Statewide Average:" in the text
statewide_position <- regexpr("(?i)Statewide Average:", snow_pack_pdf_text)
# If "Statewide Average:" is found, find the position of the numeric value after it
if (statewide_position > 0) {
# Get the substring starting from the position of "Statewide Average:"
substring_after_statewide <- substring(snow_pack_pdf_text, statewide_position)
# Extract both percentages from the matched text
statewide_percentages <- regmatches(substring_after_statewide, gregexpr("\\d+%", substring_after_statewide))[[1]]
# Print the second percentage with the desired text
if (length(statewide_percentages) >= 2) {
cat("Statewide average percent snow pack for this date", statewide_percentages[2], "\n")
} else {
cat("Second percentage after 'Statewide Average:' not found.")
}
} else {
cat("Statewide Average information not found.\n")
}
file.exists("geo_files/legal_delta.geojson")
# Load the Legal Delta boundary (replace with your actual file path)
legal_delta_boundary <- geojson_read("geo_files/legal_delta.geojson", what = "sp")
# Create the map with Legal Delta boundary and specific points
leaflet() %>%
addTiles() %>%
setView(lng = -121.5, lat = 38.05, zoom = 7) %>%  # Center the map
# Add the Legal Delta boundary polygon
addPolygons(data = legal_delta_boundary, color = "blue", weight = 2, fillOpacity = 0.5, popup = "Legal Delta Boundary") %>%
# Add specific points of interest as markers
addMarkers(lng = -121.493000, lat = 39.540000, popup = "Oroville Reservoir") %>%  # Oroville reservoir (ORO)
addMarkers(lng = 	-119.302000, lat = 	37.145000, popup = "Shasta Reservoir") %>%    # Shasta reservoir (SHA)
addMarkers(lng = -121.133000, lat = 37.033000, popup = "San Luis Reservoir")   # San Luis reservoir (SNL)
# URL of the website to scrape
reservoir_url <- "https://cdec.water.ca.gov/reportapp/javareports?name=RES"
# Read the web page
reservoir_web_page <- read_html(reservoir_url)
# Extract the table node
reservoir_table_node <- html_node(reservoir_web_page, "table")
# Extract the table content into a data frame
reservoir_table_data <- html_table(reservoir_table_node)
# Print the entire table data
print(reservoir_table_data)
# Extract a specific numbers [row, column]
# Shasta (at Sacramento River)
# extract percent of average storage
shasta_percent_average_storage_value <- as.numeric(reservoir_table_data[10, 9])
# extract percent of capacity
shasta_percent_capacity_value <- as.numeric(reservoir_table_data[10, 7])
# Print the formatted output with a Markdown header
cat(sprintf(" Shasta Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n",
shasta_percent_average_storage_value, shasta_percent_capacity_value))
# Extract a specific numbers [row, column]
# Oroville (at Feather River)
# extract percent of average storage
oroville_percent_average_storage_value <- as.numeric(reservoir_table_data[13, 9])
# extract percent of capacity
oroville_percent_capacity_value <- as.numeric(reservoir_table_data[13, 7])
# Print the formatted output (but this will be hidden)
cat(sprintf(" Oroville Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n",
oroville_percent_average_storage_value, oroville_percent_capacity_value))
# Extract a specific numbers [row, column]
# San Luis (at San Luis Creek)
# extract percent of average storage
SanLuis_percent_average_storage_value <- as.numeric(reservoir_table_data[56, 9])
# extract percent of capacity
SanLuis_percent_capacity_value <- as.numeric(reservoir_table_data[56, 7])
# Print the formatted output (but this will be hidden)
cat(sprintf(" San Luis Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n",
SanLuis_percent_average_storage_value, SanLuis_percent_capacity_value))
#map of sensors
map <- leaflet() %>%
addTiles() %>%
setView(lng = -121.5, lat = 38.05, zoom = 9) %>% # Adjust center and zoom for the Legal Delta
addMarkers(lng = -121.5, lat = 38.05, popup = "Central Delta Region") %>% # Add specific points
addMarkers(lng = -121.7, lat = 38.3, popup = "North Delta") %>%          # Another example point
addMarkers(lng = -121.3, lat = 37.9, popup = "South Delta")               # Example points
map
#map of sensors
map <- leaflet() %>%
addTiles() %>%
setView(lng = -121.5, lat = 38.05, zoom = 9) %>% # Adjust center and zoom for the Legal Delta
addMarkers(lng = -121.5, lat = 38.05, popup = "San Joaquin River at Vernalis") %>% # Add specific points
addMarkers(lng = -121.7, lat = 38.3, popup = "Sacramento") %>%          # Another example point
addMarkers(lng = -121.3, lat = 37.9, popup = "Central Valley Project and State Water Project pumping station")               # Example points
map
#map of sensors
map <- leaflet() %>%
addTiles() %>%
setView(lng = -121.5, lat = 38.05, zoom = 9) %>% # Adjust center and zoom for the Legal Delta
addMarkers(lng = -121.27, lat = 37.68, popup = "San Joaquin River near Vernalis") %>% # Add specific points
addMarkers(lng = -121.7, lat = 38.45, popup = "Sacramento at Freeport") %>%          # Another example point
addMarkers(lng = -121.3, lat = 37.9, popup = "Central Valley Project and State Water Project pumping station")
map
