---
title: "Whats going on in the Delta Wateshed"
---

------------------------------------------------------------------------

------------------------------------------------------------------------

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
rm(list=ls())

#install.packages("rvest")
library(rvest)
#install.packages("pdftools")
library(pdftools)
library(tidyverse)
library(stringr)
#install.packages("rvest")
#install.packages("xml2")
library(rvest)
library(xml2)

#install.packages("devtools")
#devtools::install_github("flowwest/CDECRetrieve")
library(CDECRetrieve)

library(magrittr)
#install.packages("leaflet")
library(leaflet)
#install.packages("writexl")
library(writexl)
#install.packages("readxl")
library(readxl)

#install.packages("lubridate")
library(lubridate)
#install.packages("openxlsx")
library(openxlsx)

library(geojsonio)



```

#################### Precipitation

Crucial to the Delta Watershed as it provides water for the Delta!

-   **Water Supply**

-   **Ecosystem Health**

-   **Agricultural Support**

-   **Flood Control**

-   **Salinity Control**

-   **Hydropower Generation**

-   **Recreation and Tourism**

```{r}

#URL of pdf file

# ***** need to see if this pdf updates everyday with the same URL *******
northern_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/PLOT_ESI.pdf"


#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded

northern_pdf_file<-"C:/Users/jweidenfeld/Desktop/Rprojects/By_The_Numbers/data_output/northern_sierra.pdf"



# Download the PDF file

# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(northern_pdf_url, northern_pdf_file, mode = "wb")

# Extract text from the PDF
northern_pdf_text <- pdf_text(northern_pdf_file)

# Print the extracted text
#print(northern_pdf_text)

```

###### Current Precipitation for Northern Sierra Region {style="color: darkblue"}

```{r}

# Initialize an empty vector to store the extracted values
N_sierra_current_precip <- c()

# Extract text from the PDF file
northern_pdf_text <- pdf_text(northern_pdf_file)

# Print the next four characters following "Current:" in each sentence
if (length(northern_pdf_text) > 0) {
  for (sentence in northern_pdf_text) {
    pattern <- "(?i)Current:\\s?(.{4})"
    match <- regexpr(pattern, sentence, perl = TRUE)
    if (match[1] != -1) {
      northern_next_four <- regmatches(sentence, match)
      # Extract the captured group (the four characters) and append to the vector
      next_four <- sub(pattern, "\\1", northern_next_four)
      N_sierra_current_precip <- c(N_sierra_current_precip, next_four)
      # Print the formatted output as "Current: <next_four>"
      cat(paste("Current:", next_four, "inches"))
    } else {
      cat("Next four characters after 'Current:' not found.")
    }
  }
} else {
  cat("No text extracted from the PDF.")
}




```

Northern Sierra Region: Percent of average rain for this date

```{r}
# Create an empty vector to store the extracted value
N_sierra_average_precip <- c()

# Extract text from the PDF file
northern_pdf_text <- pdf_text(northern_pdf_file)

# Check if the PDF text is not empty
if (length(northern_pdf_text) > 0) {
  # Concatenate all the text into a single string
  combined_text <- paste(northern_pdf_text, collapse = " ")
  
  # Define the pattern to match the "Percent of Average for this Date:" followed by the percentage value
  pattern <- "(?i)Percent of Average for this Date:\\s*(\\d+%)"
  
  # Extract the match using regmatches and regexpr
  northern_next_four <- regmatches(combined_text, regexpr(pattern, combined_text, perl = TRUE))
  
  if (length(northern_next_four) > 0) {
    # Extract the percentage value using a capturing group
    percent_value <- sub("(?i)Percent of Average for this Date:\\s*(\\d+%)", "\\1", northern_next_four)
    
    # Append the value to the vector
    N_sierra_average_precip <- c(N_sierra_average_precip, percent_value)
    
    # Print only the percentage value
    cat(percent_value, "\n")
  } else {
    cat("Percent of Average for this Date not found.\n")
  }
} else {
  cat("No text extracted from the PDF.\n")
}



```

#### Central Sierra {style="color: darkblue"}

###### Current Precipitation for Central Sierra Region {style="color: darkblue"}

Current Precipitation for Central Sierra Region

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

#Central Sierra precipitation #Pulling and downloading the pdf from online
#URL of pdf file

# ***** need to see if this pdf updates everyday with the same URL *******
central_ppt_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/PLOT_FSI.pdf"


#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded
central_ppt_pdf_file2<-"C:/Users/jweidenfeld/Desktop/Rprojects/By_The_Numbers/data_output/central_sierra2.pdf"

# Download the PDF file

# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(central_ppt_pdf_url, central_ppt_pdf_file2, mode = "wb")

# Extract text from the PDF
central_pdf_text <- pdf_text(central_ppt_pdf_file2)

# Print the extracted text
print(central_pdf_text)

```

```{r}
#create an empty vector 
Central_current_precip <- c()

# Adjusted pattern for "Current:"
if (length(central_pdf_text) > 0) {
  for (sentence in central_pdf_text) {
    pattern <- "(?i)Current[:\\s]+(.{4})"
    next_four <- regmatches(sentence, regexpr(pattern, sentence, perl = TRUE))
    if (length(next_four) > 0) {
      # Append the value of next_four to the vector
      Central_current_precip <- c(Central_current_precip, next_four)
      cat(paste(next_four, "inches\n"))
    } else {
      cat("Next four characters after 'Current:' not found.\n")
    }
  }
} else {
  cat("No text extracted from the PDF.")
}


```

Central Sierra Region: Percent of average rain for this date

```{r}

#Central Sierra #PUlling out Percent average

#create an empty vector
Central_average_precip <- c()

# Adjusted pattern for "Percent of Average for this Date:"
if (length(central_pdf_text) > 0) {
  for (sentence in central_pdf_text) {
    pattern <- "(?i)Percent of Average for this Date[:\\s]+(.{4})"
    next_four <- regmatches(sentence, regexpr(pattern, sentence, perl = TRUE))
    if (length(next_four) > 0) {
      # Append the value of next_four to the vector
      Central_average_precip <- c(Central_average_precip, next_four)
      cat(paste(next_four, "\n"))
    } else {
      cat("Next four characters after 'Percent of Average for this Date:' not found.\n")
    }
  }
} else {
  cat("No text extracted from the PDF.")
}



```

#################################################################################### 

#################### SNOW PACK

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
#URL of pdf file

# ***** need to see if this pdf updates everyday with the same URL *******
snow_pack_pdf_url <- "https://cdec.water.ca.gov/cgi-progs/products/swccond.pdf"


#pathway to where you want the pdf to be saved
#can eventaully make the name of the pdf with the date it is downloaded
snow_pack_pdf_file<-"C:/Users/jweidenfeld/Desktop/Rprojects/By_The_Numbers/data_output/snow_pack.pdf"

# Download the PDF file

# The "wb" mode is typically used when downloading non-text files, such as images, PDFs, or other binary files. It tells R to open the file in binary mode, which is necessary for correctly handling binary data
download.file(snow_pack_pdf_url, snow_pack_pdf_file, mode = "wb")

# Extract text from the PDF
snow_pack_pdf_text <- pdf_text(snow_pack_pdf_file)

# Print the extracted text
print(snow_pack_pdf_text)


```

#North Snow average snow pack

```{r}
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)NORTH\\s{2,}(\\d+%).*?(\\d+%)"

# Extract the "NORTH" section
north_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))

# Check if the "NORTH" section is found
if (length(north_match) > 0) {
  # Extract both percentages from the matched text
  north_percentages <- regmatches(north_match[[1]], gregexpr("\\d+%", north_match[[1]]))[[1]]
  
  # Print the extracted percentage
  if (length(north_percentages) >= 2) {
    cat(paste("Northern CA:", north_percentages[2], "of percent avgerage to date snow pack"))
  } else {
    cat("Second percentage in the 'NORTH' section not found.")
  }
} else {
  cat("NORTH section not found.")
}

```

#north snow water equivalent

```{r}

# Define the pattern to match the line containing the snow water equivalent information
pattern <- "(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)"

# Extract the line containing snow water equivalent information
snow_water_line <- regmatches(snow_pack_pdf_text, regexpr(pattern, snow_pack_pdf_text, perl = TRUE))

# Check if the line is found
if (length(snow_water_line) > 0) {
  # Extract the numeric value
  numeric_value <- sub("(?i)Average snow water equivalent \\(Inches\\)\\s+(\\d+\\.\\d+)", "\\1", snow_water_line)
  
  # Create the modified line with "inches" after the numeric value
  modified_snow_water_line <- paste("average snow water equivalent", numeric_value, "inches")
  
  cat("Northern Sierra", modified_snow_water_line, "\n")
} else {
  cat("Snow water equivalent information not found.\n")
}


```

#Central % Snow average snow pack

```{r}
# Define the pattern to match the line containing "NORTH" and the associated percentages
pattern <- "(?i)CENTRAL SIERRA\\s{2,}(\\d+%).*?(\\d+%)"

# Extract the "CENTRAL SIERRA" section
central_match <- regmatches(snow_pack_pdf_text, regexec(pattern, snow_pack_pdf_text, perl = TRUE))

# Check if the "CENTRAL SIERRA" section is found
if (length(central_match) > 0) {
  # Extract both percentages from the matched text
  central_percentages <- regmatches(central_match[[1]], gregexpr("\\d+%", central_match[[1]]))[[1]]
  
  # Print the extracted percentage
  if (length(central_percentages) >= 2) {
    cat(paste("CENTRAL SIERRA", central_percentages[2], "of percent avg. to date snow pack"))
  } else {
    cat("Second percentage in the 'CENTRAL SIERRA' section not found.")
  }
} else {
  cat("CENTRAL SIERRA section not found.")
}


```

#Central snow water equivalent

```{r}


# Find the position of "Central Sierra" in the text
central_sierra_position <- regexpr("(?i)Central Sierra", snow_pack_pdf_text)

# If "Central Sierra" is found, find the position of "Average snow water equivalent (Inches)" after it
if (central_sierra_position > 0) {
  # Get the substring starting from the position of "Central Sierra"
  substring_after_central <- substring(snow_pack_pdf_text, central_sierra_position)
  
  # Find the position of "Average snow water equivalent (Inches)" within the substring
  snow_water_position <- regexpr("(?i)Average snow water equivalent \\(Inches\\)", substring_after_central)
  
  # If "Average snow water equivalent (Inches)" is found, extract the numeric value following it
  if (snow_water_position > 0) {
    # Get the substring starting from the position of "Average snow water equivalent (Inches)"
    snow_water_substring <- substring(substring_after_central, snow_water_position)
    
    # Extract the numeric value following "Average snow water equivalent (Inches)"
    snow_water_value <- regmatches(snow_water_substring, regexpr("\\d+\\.\\d+", snow_water_substring))
    
    # If a numeric value is found, print it with the desired text
    if (length(snow_water_value) > 0) {
      cat(paste("Central snow water equivalent", snow_water_value))
    } else {
      cat("Snow water equivalent value not found.")
    }
  } else {
    cat("Average snow water equivalent information not found for Central Sierra.")
  }
} else {
  cat("Central Sierra information not found.")
}


```

# State wide average snow pack: water year

```{r}

# Find the position of "State" in the text
state_position <- regexpr("(?i)State", snow_pack_pdf_text)

# If "State" is found, find the position of the numeric value after it
if (state_position > 0) {
  # Get the substring starting from the position of "State"
  substring_after_state <- substring(snow_pack_pdf_text, state_position)
  
  # Extract the numeric value following "State"
  snow_water_value <- regmatches(substring_after_state, regexpr("\\d+\\.\\d+", substring_after_state))
  
  # If a numeric value is found, print it with the desired text
  if (length(snow_water_value) > 0) {
    cat(paste("State wide average snow pack", snow_water_value))
  } else {
    cat("Snow water equivalent value not found.")
  }
} else {
  cat("State information not found.")
}


```

#Percent of normal snow pack for this date (%)

```{r}

# Find the position of "Statewide Average:" in the text
statewide_position <- regexpr("(?i)Statewide Average:", snow_pack_pdf_text)

# If "Statewide Average:" is found, find the position of the numeric value after it
if (statewide_position > 0) {
  # Get the substring starting from the position of "Statewide Average:"
  substring_after_statewide <- substring(snow_pack_pdf_text, statewide_position)
  
  # Extract both percentages from the matched text
  statewide_percentages <- regmatches(substring_after_statewide, gregexpr("\\d+%", substring_after_statewide))[[1]]
  
  # Print the second percentage with the desired text
  if (length(statewide_percentages) >= 2) {
    cat("Statewide average percent snow pack for this date", statewide_percentages[2], "\n")
  } else {
    cat("Second percentage after 'Statewide Average:' not found.")
  }
} else {
  cat("Statewide Average information not found.\n")
}



```

# Reservoir Storage

```{r}
file.exists("geo_files/legal_delta.geojson")
# Load the Legal Delta boundary (replace with your actual file path)
legal_delta_boundary <- geojson_read("geo_files/legal_delta.geojson", what = "sp")

# Create the map with Legal Delta boundary and specific points
leaflet() %>%
  addTiles() %>%
  setView(lng = -121.5, lat = 38.05, zoom = 7) %>%  # Center the map

  # Add the Legal Delta boundary polygon
  addPolygons(data = legal_delta_boundary, color = "blue", weight = 2, fillOpacity = 0.5, popup = "Legal Delta Boundary") %>%
  
  # Add specific points of interest as markers
  addMarkers(lng = -121.493000, lat = 39.540000, popup = "Oroville Reservoir") %>%  # Oroville reservoir (ORO)
  addMarkers(lng = 	-119.302000, lat = 	37.145000, popup = "Shasta Reservoir") %>%    # Shasta reservoir (SHA)
  addMarkers(lng = -121.133000, lat = 37.033000, popup = "San Luis Reservoir")   # San Luis reservoir (SNL)



```

##### shaded area on map is the legal delta

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

# URL of the website to scrape
reservoir_url <- "https://cdec.water.ca.gov/reportapp/javareports?name=RES"

# Read the web page
reservoir_web_page <- read_html(reservoir_url)

# Extract the table node
reservoir_table_node <- html_node(reservoir_web_page, "table")

# Extract the table content into a data frame
reservoir_table_data <- html_table(reservoir_table_node)

# Print the entire table data
print(reservoir_table_data)

```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Extract a specific numbers [row, column]
# Shasta (at Sacramento River)

# extract percent of average storage
shasta_percent_average_storage_value <- as.numeric(reservoir_table_data[10, 9])

# extract percent of capacity
shasta_percent_capacity_value <- as.numeric(reservoir_table_data[10, 7])


# Print the formatted output with a Markdown header
cat(sprintf(" Shasta Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n", 
    shasta_percent_average_storage_value, shasta_percent_capacity_value))


```

### Shasta Reservoir: `r shasta_percent_average_storage_value`% of average storage, `r shasta_percent_capacity_value`% of total capacity.

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Extract a specific numbers [row, column]
# Oroville (at Feather River)

# extract percent of average storage
oroville_percent_average_storage_value <- as.numeric(reservoir_table_data[13, 9])

# extract percent of capacity
oroville_percent_capacity_value <- as.numeric(reservoir_table_data[13, 7])

# Print the formatted output (but this will be hidden)
cat(sprintf(" Oroville Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n", 
    oroville_percent_average_storage_value, oroville_percent_capacity_value))

```

### Oroville Reservoir: `r oroville_percent_average_storage_value`% of average storage, `r oroville_percent_capacity_value`% of total capacity.

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

# Extract a specific numbers [row, column]
# San Luis (at San Luis Creek)

# extract percent of average storage
SanLuis_percent_average_storage_value <- as.numeric(reservoir_table_data[56, 9])

# extract percent of capacity
SanLuis_percent_capacity_value <- as.numeric(reservoir_table_data[56, 7])

# Print the formatted output (but this will be hidden)
cat(sprintf(" San Luis Reservoir: %.0f%% of average storage, %.0f%% of total capacity.\n", 
    SanLuis_percent_average_storage_value, SanLuis_percent_capacity_value))

```

### San Luis Reservoir: `r SanLuis_percent_average_storage_value`% of average storage, `r SanLuis_percent_capacity_value`% of total capacity.




################### Flow Sacramento

#collapsed code chunk makes a bad map of sacramento sensors



```{r}

map <- leaflet() %>%
  addTiles() %>%
  setView(lng = -121.5, lat = 38.05, zoom = 9) %>% # Adjust center and zoom for the Legal Delta
  addMarkers(lng = -121.5, lat = 38.05, popup = "Central Delta Region") %>% # Add specific points
  addMarkers(lng = -121.7, lat = 38.3, popup = "North Delta") %>%          # Another example point
  addMarkers(lng = -121.3, lat = 37.9, popup = "South Delta")               # Example points
map

```

#Sacramento mean monthly flow
```{r}



# File path to your Excel file
sacramento_file_path <- "historical_data/historical_data_full.xlsx"

# Determine the current month and year
# %b is the month in short form
# %Y is the year
# Sys.Date() pulls the date from whatever system the program is on
sacramento_current_month <- format(Sys.Date(), "%b")
sacramento_current_year <- format(Sys.Date(), "%Y")

# Load the entire workbook without overwriting other sheets
sacramento_workbook <- loadWorkbook(sacramento_file_path)

# Read the specific sheet you want to update
sacramento_historical_data <- readWorkbook(sacramento_workbook, sheet = "Flow_Sac")
sacramento_historical_data$Year <- as.character(sacramento_historical_data$Year) # Ensure Year is character

# Calculate the new value you want to add (e.g., CFS average)
sacramento_start_date <- floor_date(Sys.Date(), "month")
sacramento_end_date <- Sys.Date()

# Query CDEC data for San Joaquin at Vernalis (station "VNS") for the current month
# Assuming `cdec_query` returns a data frame with a "parameter_value" column
sacramento_flow_daily <- cdec_query(station = "FPT", sensor_num = 20, 
                                     dur_code = "H", start_date = as.character(sacramento_start_date), 
                                     end_date = as.character(sacramento_end_date))


# Assume `sacramento_flow_daily` is generated from CDEC data query
sacramento_current_month_CFS_average <- mean(sacramento_flow_daily$parameter_value, na.rm = TRUE)

# Check if there is an entry for the current month and year
existing_entry <- sacramento_historical_data %>%
  filter(Month == sacramento_current_month, Year == sacramento_current_year)

if (nrow(existing_entry) > 0) {
  # Update the existing row with the new CFS average for the current month
  row_to_update <- which(sacramento_historical_data$Month == sacramento_current_month & 
                         sacramento_historical_data$Year == sacramento_current_year)
  sacramento_historical_data[row_to_update, "Average_Flow_Daily"] <- sacramento_current_month_CFS_average
} else {
  # Create a new row with the current month, year, and average flow if it's a new month
  new_row <- data.frame(
    Month = sacramento_current_month,
    Year = sacramento_current_year,
    Average_Flow_Daily = sacramento_current_month_CFS_average
  )
  
  # Append the new row to the historical data
  sacramento_historical_data <- bind_rows(sacramento_historical_data, new_row)
}

# Write only the modified sheet back to the workbook
writeData(sacramento_workbook, sheet = "Flow_Sac", x = sacramento_historical_data)

# Save the workbook, preserving all other sheets
saveWorkbook(sacramento_workbook, sacramento_file_path, overwrite = TRUE)

message("File updated successfully with current month's data.")


```
#  San Joaquin River at Vernalis Flow
```{r}

# File path to your Excel file (the one you just uploaded)
san_joaquin_file_path <- "historical_data/historical_data_full.xlsx"

# Determine the current month and year
san_joaquin_current_month <- format(Sys.Date(), "%b")
san_joaquin_current_year <- format(Sys.Date(), "%Y")

# Load the entire workbook without overwriting other sheets
san_joaquin_workbook <- loadWorkbook(san_joaquin_file_path)

# Read the specific sheet you want to update
san_joaquin_historical_data <- readWorkbook(san_joaquin_workbook, sheet = "Flow_SanJoaq")
san_joaquin_historical_data$Year <- as.character(san_joaquin_historical_data$Year) # Ensure Year is character

# Define the start and end dates for the current month
san_joaquin_start_date <- floor_date(Sys.Date(), "month")
san_joaquin_end_date <- Sys.Date()

# Query CDEC data for San Joaquin at Vernalis (station "VNS") for the current month
# Assuming `cdec_query` returns a data frame with a "parameter_value" column
san_joaquin_flow_daily <- cdec_query(station = "VNS", sensor_num = 20, 
                                     dur_code = "H", start_date = as.character(san_joaquin_start_date), 
                                     end_date = as.character(san_joaquin_end_date))

# Calculate the monthly average for San Joaquin flow
san_joaquin_export_monthly_average <- mean(san_joaquin_flow_daily$parameter_value, na.rm = TRUE)

# Calculate the historical mean for the current month, if available in your data
san_joaquin_current_month_historical_data <- san_joaquin_historical_data %>%
  filter(Month == san_joaquin_current_month) %>%
  select(Average_Flow_Daily)

san_joaquin_current_month_historical_mean <- mean(san_joaquin_current_month_historical_data$Average_Flow_Daily, na.rm = TRUE)

# Calculate the percentage of the current monthâ€™s average relative to the historical average
san_joaquin_percentage_of_cfs_average <- (san_joaquin_export_monthly_average / san_joaquin_current_month_historical_mean) * 100

# Print only the percentage result
message(sprintf("San Joaquin export monthly average is %.2f%% of the historical average for %s", 
                san_joaquin_percentage_of_cfs_average, san_joaquin_current_month))

# Check if there is an entry for the current month and year
existing_entry <- san_joaquin_historical_data %>%
  filter(Month == san_joaquin_current_month, Year == san_joaquin_current_year)

suppressMessages({
  if (nrow(existing_entry) > 0) {
    # Update the existing row with the new flow average for the current month
    row_to_update <- which(san_joaquin_historical_data$Month == san_joaquin_current_month & 
                           san_joaquin_historical_data$Year == san_joaquin_current_year)
    san_joaquin_historical_data[row_to_update, "Average_Flow_Daily"] <- san_joaquin_export_monthly_average
  } else {
    # Create a new row with the current month, year, and flow average if it's a new month
    new_row <- data.frame(
      Month = san_joaquin_current_month,
      Year = san_joaquin_current_year,
      Average_Flow_Daily = san_joaquin_export_monthly_average
    )
    
    # Append the new row to the historical data
    san_joaquin_historical_data <- bind_rows(san_joaquin_historical_data, new_row)
  }
  
  # Write only the modified sheet back to the workbook
  writeData(san_joaquin_workbook, sheet = "Flow_SanJoaq", x = san_joaquin_historical_data)
  
  # Save the workbook, preserving all other sheets
  saveWorkbook(san_joaquin_workbook, san_joaquin_file_path, overwrite = TRUE)
})



```


#Total Delta Exports: 'total delta exports', average of (CVP + SWP)

#### work in progress
```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}



# URL of the PDF file
delta_exports_pdf_url <- "https://www.usbr.gov/mp/cvo/vungvari/doutdly.pdf"

# Path to save the downloaded PDF file
delta_exports_pdf_file <- "historical_data/delta_exports.pdf"

# Download the PDF file
download.file(delta_exports_pdf_url, delta_exports_pdf_file, mode = "wb")

# Extract text from the PDF file
delta_exports_pdf_text <- pdf_text(delta_exports_pdf_file)

# Extract the last page's text, where the "Average" row appears
delta_export_last_page_text <- delta_exports_pdf_text[length(delta_exports_pdf_text)]

# Split the text into lines
delta_export_lines <- str_split(delta_export_last_page_text, "\n")[[1]]

# Find the line containing the "Average" row
delta_export_average_line <- delta_export_lines[str_detect(delta_export_lines, "Average")]

# Print the line to verify the content and ensure we're targeting the right row
print(delta_export_average_line)

# Refine the regular expression to match specific numeric values, using longer patterns if possible
delta_export_values <- str_extract_all(delta_export_average_line, "\\b\\d{4,5}\\b")[[1]]  # Look for 4- or 5-digit numbers

# Inspect extracted values to identify the target (in this case, 5259 is expected)
print(delta_export_values)

# Assuming the correct index is known based on inspection, retrieve the value (e.g., 5259)
average_delta_export_value <- as.numeric(delta_export_values[1])  # Adjust the index if necessary
print(average_delta_export_value)

# Excel file path and current date
excel_file_path <- "historical_data/historical_data_full.xlsx"
current_month <- format(Sys.Date(), "%b")
current_year <- format(Sys.Date(), "%Y")

# Load the workbook and the specific sheet
delta_exports_workbook <- loadWorkbook(excel_file_path)
delta_exports_data <- readWorkbook(delta_exports_workbook, sheet = "Total_Delta_Exports")

# Ensure the Year column is character to match with the new data format
delta_exports_data$Year <- as.character(delta_exports_data$Year)

# Check if there's already an entry for the current month and year
existing_entry <- delta_exports_data %>%
  filter(Month == current_month, Year == current_year)

if (nrow(existing_entry) > 0) {
  # Update the existing row with the new average Delta Exports value
  row_to_update <- which(delta_exports_data$Month == current_month & 
                         delta_exports_data$Year == current_year)
  delta_exports_data[row_to_update, "Exports"] <- average_delta_export_value
} else {
  # Add a new row if it's a new month
  new_row <- data.frame(
    Month = current_month,
    Year = current_year,
    Exports = average_delta_export_value
  )
  
  # Append the new row
  delta_exports_data <- bind_rows(delta_exports_data, new_row)
}

# Write the updated sheet back to the workbook
writeData(delta_exports_workbook, sheet = "Total_Delta_Exports", x = delta_exports_data)

# Save the workbook, preserving all sheets
saveWorkbook(delta_exports_workbook, excel_file_path, overwrite = TRUE)

message("Delta Exports data updated successfully for the current month.")


```



##\*\*\* figure out way to add data from this year to historical after year ends #somethign that updates only on specific dates #Need to create a output csv file for historical data

```{r}
# read_xlxs() by default reads in the first sheet. There may however be numerous sheets in the file. We can tell R which sheet to read in as well as how many lines to skip before reading in data

#tells R to skip 6 lines and then read in the second sheet of an xlsx file
#metadata<-read_xlsx("data/calenviroscreen/ces3results.xlsx", 
 #                     sheet = 2, 
  #                    skip  = 6)

#as of now data has to be added manually at the end of the year to the historical data set

```

################################## Salinity

#Sacramento River at Hood (station code SRH) #When run, will automatically update for current month

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
sac_cond_daily_new <- cdec_query(station = "SRH", sensor_num = "100", 
                             dur_code = "D", start_date = as.character(start_date), 
                             end_date = as.character(end_date))
Sac_cond_monthly_average<-mean(sac_cond_daily_new$parameter_value, na.rm = T)
Sac_cond_monthly_average

#### ppm conversion
sac_ppm<-(Sac_cond_monthly_average*0.55)


```

#San Joaquin River at Vernalis (station code - VER) #When run, will automatically update for current month

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SanJoaquin_cond_daily_new <- cdec_query(station = "VER", sensor_num = "100", 
                             dur_code = "D", start_date = as.character(start_date), 
                             end_date = as.character(end_date))


SanJoaquin_cond_monthly_average<-mean(SanJoaquin_cond_daily_new$parameter_value, na.rm = T)
SanJoaquin_cond_monthly_average

#### ppm conversion
SanJoa_ppm<-(SanJoaquin_cond_monthly_average*0.55)
SanJoa_ppm
```

#Salinity at Banks pumping plant (station code - HBP) #When run, will automatically update for current month

```{r}


# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
Banks_cond_daily_new <- cdec_query(station = "HBP", sensor_num = "100", 
                             dur_code = "D", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#need to take the average of all parameter_value for the date 
Banks_cond_monthly_average<-mean(Banks_cond_daily_new$parameter_value, na.rm = T)
Banks_cond_monthly_average


#convert um/cm to ppm
#idea to have some historical context with the salinity?
#### ppm conversion
Banks_ppm<-(Banks_cond_monthly_average*0.55)
Banks_ppm
```

####################### TEMPERATURE

#need to add hisotrical average data in --\> will add to csv file eventually

#Water Temp - Sacramento river headwaters at Clear Creek

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SacClearCreek_waterTemp_new <- cdec_query(station = "IGO", sensor_num = "25", 
                             dur_code = "H", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#need to take the average of all parameter_value for the date 
SacClearCreek_waterTemp_monthly_average<-mean(SacClearCreek_waterTemp_new$parameter_value, na.rm = T)
SacClearCreek_waterTemp_monthly_average



#cdec_datasets("IGO")

```

#Water Temp - Sacramento/San Joaquin Rivers confluence at Collinsville

```{r}

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SacSanJoaquin_waterTemp_new <- cdec_query(station = "CSE", sensor_num = "25", 
                             dur_code = "H", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#need to take the average of all parameter_value for the date 
SacSanJoaquin_waterTemp_monthly_average<-mean(SacSanJoaquin_waterTemp_new$parameter_value, na.rm = T)
SacSanJoaquin_waterTemp_monthly_average


```

```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

#Water Temp - South Delta (near HBP) at Clifton Court Forebay

cdec_datasets("CLC")

# Get the first day of the current month
start_date <- floor_date(Sys.Date(), "month")

# Get the current date
end_date <- Sys.Date()

# Query CDEC data from the first of the month to the current date
SouthDelta_waterTemp_new <- cdec_query(station = "CLC", sensor_num = "146", 
                             dur_code = "H", start_date = as.character(start_date), 
                             end_date = as.character(end_date))



#because CLC temp gage only have readings in Celcius, need to convert to F

SouthDelta_waterTemp_new$parameter_F<-(SouthDelta_waterTemp_new$parameter_value*( 9/5) + 32)
```

#Water Temp - South Delta (near HBP) at Clifton Court Forebay

```{r}
#need to take the average of all parameter_value for the date 
SouthDelta_waterTemp_monthly_average_F<-mean(SouthDelta_waterTemp_new$parameter_F, na.rm = T)
SouthDelta_waterTemp_monthly_average_F

```
